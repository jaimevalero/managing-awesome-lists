{"category_type":"topic","category_name":"llmops","repos_data":[{"full_name":"vllm-project/vllm","description":"A high-throughput and memory-efficient inference and serving engine for LLMs","topics":["gpt","llm","pytorch","llmops","mlops","model-serving","transformer","llm-serving","inference","llama"],"created_at":"2023-02-09T11:23:20Z","pushed_at":"2024-01-13T09:57:40Z","stargazers_count":13145,"language":"Python"},{"full_name":"bentoml/OpenLLM","description":"Operating LLMs in production","topics":["llm","llmops","model-inference","falcon","fine-tuning","stablelm","llm-serving","llama","mpt","vicuna"],"created_at":"2023-04-19T00:27:52Z","pushed_at":"2024-01-12T19:56:06Z","stargazers_count":7550,"language":"Python"},{"full_name":"tensorchord/envd","description":"üèïÔ∏è Reproducible development environment","topics":["developer-tools","development-environment","docker","buildkit","hacktoberfest","llmops","mlops","mlops-workflow","model-serving"],"created_at":"2022-04-11T09:04:19Z","pushed_at":"2024-01-08T02:26:05Z","stargazers_count":1856,"language":"Makefile"},{"full_name":"promptfoo/promptfoo","description":"Test your prompts, models, RAGs. Evaluate and compare LLM outputs, catch regressions, and improve prompt quality. LLM evals for OpenAI/Azure GPT, Anthropic Claude, VertexAI Gemini, Ollama, Local & private models like Mistral/Mixtral/Llama with CI/CD","topics":["llm","prompt-engineering","prompts","llmops","prompt-testing","testing","rag","evaluation","evaluation-framework","llm-eval"],"created_at":"2023-04-28T15:48:49Z","pushed_at":"2024-01-20T00:45:30Z","stargazers_count":1748,"language":"TypeScript"},{"full_name":"Agenta-AI/agenta","description":"The all-in-one LLMOps platform: prompt management, evaluation, human feedback, and deployment all in one place.","topics":["langchain","llmops","large-language-models","llm","llm-tools","llms","prompt-engineering","prompt-management","llama-index","llm-evaluation"],"created_at":"2023-04-26T09:54:28Z","pushed_at":"2024-01-19T21:03:46Z","stargazers_count":636,"language":"Dockerfile"}],"frecuent_topics":{"llmops":5,"llm":4,"mlops":2,"model-serving":2,"llm-serving":2}}