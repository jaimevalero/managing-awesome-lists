{"category_type":"topic","category_name":"llama","repos_data":[{"full_name":"jmorganca/ollama","description":"Get up and running with Llama 2, Mistral, and other large language models locally.","topics":["llama","llm","llama2","llms","go","golang","ollama","mistral"],"created_at":"2023-06-26T19:39:32Z","pushed_at":"2024-01-13T08:53:00Z","stargazers_count":30871,"language":"TypeScript"},{"full_name":"mudler/LocalAI","description":":robot: The free, Open Source OpenAI alternative. Self-hosted, community-driven and local-first. Drop-in replacement for OpenAI running on consumer-grade hardware. No GPU required. Runs ggml, gguf, GPTQ, onnx, TF compatible models: llama, llama2, rwkv, whisper, vicuna, koala, cerebras, falcon, dolly, starcoder, and many others","topics":["alpaca","gpt-neox","llama","rwkv","vicuna","ai","llm","stable-diffusion","api","api-rest"],"created_at":"2023-03-18T22:58:02Z","pushed_at":"2024-01-13T09:08:27Z","stargazers_count":15354,"language":"Earthly"},{"full_name":"vllm-project/vllm","description":"A high-throughput and memory-efficient inference and serving engine for LLMs","topics":["gpt","llm","pytorch","llmops","mlops","model-serving","transformer","llm-serving","inference","llama"],"created_at":"2023-02-09T11:23:20Z","pushed_at":"2024-01-13T09:57:40Z","stargazers_count":13145,"language":"Python"},{"full_name":"bentoml/OpenLLM","description":"Operating LLMs in production","topics":["llm","llmops","model-inference","falcon","fine-tuning","stablelm","llm-serving","llama","mpt","vicuna"],"created_at":"2023-04-19T00:27:52Z","pushed_at":"2024-01-12T19:56:06Z","stargazers_count":7550,"language":"Python"},{"full_name":"Mintplex-Labs/anything-llm","description":"Open-source ChatGPT experience for LLMs, embedders, and vector databases. Unlimited documents, messages, and concurrent users with permission management in one app.","topics":["chatgpt-app","chroma","langchain","openai-chatgpt","pinecone","llama","mistral-7b","rag","retrieval-augmented-generation","document-chat"],"created_at":"2023-06-04T02:29:14Z","pushed_at":"2024-01-13T08:32:44Z","stargazers_count":7326,"language":"Shell"},{"full_name":"LianjiaTech/BELLE","description":"BELLE: Be Everyone's Large Language model Engine（开源中文对话大模型）","topics":["bloom","instruction-set","llama","open-models","gpt-q","instruct-gpt","gpt-evaluation","chinese-nlp","lora","instruct-finetune"],"created_at":"2023-03-17T09:44:11Z","pushed_at":"2023-12-29T08:39:14Z","stargazers_count":7153,"language":"Python"},{"full_name":"serge-chat/serge","description":"A web interface for chatting with Alpaca through llama.cpp. Fully dockerized, with an easy to use API.","topics":["llama","alpaca","docker","fastapi","llamacpp","python","web","svelte","sveltekit","tailwindcss"],"created_at":"2023-03-19T08:33:29Z","pushed_at":"2024-01-13T00:43:39Z","stargazers_count":5360,"language":"Python"},{"full_name":"HqWu-HITCS/Awesome-Chinese-LLM","description":"整理开源的中文大语言模型，以规模较小、可私有化部署、训练成本较低的模型为主，包括底座模型，垂直领域微调及应用，数据集与教程等。","topics":["llm","nlp","chatglm","chinese","llama","awesome-lists"],"created_at":"2023-05-22T12:27:03Z","pushed_at":"2023-12-27T14:19:30Z","stargazers_count":5327,"language":"unknown"},{"full_name":"Facico/Chinese-Vicuna","description":"Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model —— 一个中文低资源的llama+lora方案，结构参考alpaca","topics":["llama","alpaca","chinese","vicuna"],"created_at":"2023-03-23T01:54:50Z","pushed_at":"2023-12-21T08:37:06Z","stargazers_count":4099,"language":"Python"},{"full_name":"higgsfield-ai/higgsfield","description":"Fault-tolerant, highly scalable GPU orchestration, and a machine learning framework designed for training models with billions to trillions of parameters","topics":["cluster-management","deep-learning","distributed","llama","llama2","llm","machine-learning","mlops","pytorch"],"created_at":"2018-05-26T22:47:43Z","pushed_at":"2024-01-11T21:33:13Z","stargazers_count":3213,"language":"Jupyter Notebook"},{"full_name":"zjunlp/KnowLM","description":"An Open-sourced Knowledgable Large Language Model Framework.","topics":["llama","large-language-models","pre-trained-language-models","language-model","instruction-following","deep-learning","chinese","english","instructions","models"],"created_at":"2023-04-01T03:45:31Z","pushed_at":"2024-01-19T05:20:33Z","stargazers_count":866,"language":"Python"},{"full_name":"GaryYufei/AlignLLMHumanSurvey","description":"Aligning Large Language Models with Human: A Survey","topics":["chatgpt","gpt-4","large-language-models","llms","rlhf","supervised-finetuning","survey","awesome","chinese-llama","llama"],"created_at":"2023-07-23T06:41:56Z","pushed_at":"2023-09-11T03:38:05Z","stargazers_count":522,"language":"unknown"},{"full_name":"pleisto/flappy","description":"Production-Ready LLM Agent SDK for Every Developer","topics":["agent","chatgpt","generative-ai","llm","rewoo","llama","transformers"],"created_at":"2023-09-15T18:09:15Z","pushed_at":"2024-01-11T02:44:26Z","stargazers_count":284,"language":"Rust"}],"frecuent_topics":{"llama":13,"llm":7,"alpaca":3,"vicuna":3,"chinese":3}}