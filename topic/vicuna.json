{"category_type":"topic","category_name":"vicuna","repos_data":[{"full_name":"mudler/LocalAI","description":":robot: The free, Open Source OpenAI alternative. Self-hosted, community-driven and local-first. Drop-in replacement for OpenAI running on consumer-grade hardware. No GPU required. Runs ggml, gguf, GPTQ, onnx, TF compatible models: llama, llama2, rwkv, whisper, vicuna, koala, cerebras, falcon, dolly, starcoder, and many others","topics":["alpaca","gpt-neox","llama","rwkv","vicuna","ai","llm","stable-diffusion","api","api-rest"],"created_at":"2023-03-18T22:58:02Z","pushed_at":"2024-01-13T09:08:27Z","stargazers_count":15354,"language":"Earthly"},{"full_name":"bentoml/OpenLLM","description":"Operating LLMs in production","topics":["llm","llmops","model-inference","falcon","fine-tuning","stablelm","llm-serving","llama","mpt","vicuna"],"created_at":"2023-04-19T00:27:52Z","pushed_at":"2024-01-12T19:56:06Z","stargazers_count":7550,"language":"Python"},{"full_name":"Facico/Chinese-Vicuna","description":"Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model —— 一个中文低资源的llama+lora方案，结构参考alpaca","topics":["llama","alpaca","chinese","vicuna"],"created_at":"2023-03-23T01:54:50Z","pushed_at":"2023-12-21T08:37:06Z","stargazers_count":4099,"language":"Python"}],"frecuent_topics":{"llama":3,"vicuna":3,"alpaca":2,"llm":2,"gpt-neox":1}}