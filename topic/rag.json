{"category_type":"topic","category_name":"rag","repos_data":[{"full_name":"run-llama/llama_index","description":"LlamaIndex (formerly GPT Index) is a data framework for your LLM applications","topics":["agents","application","data","fine-tuning","framework","llamaindex","llm","rag","vector-database"],"created_at":"2022-11-02T04:24:54Z","pushed_at":"2024-01-21T13:17:31Z","stargazers_count":26992,"language":"Python"},{"full_name":"Mintplex-Labs/anything-llm","description":"Open-source ChatGPT experience for LLMs, embedders, and vector databases. Unlimited documents, messages, and concurrent users with permission management in one app.","topics":["chatgpt-app","chroma","langchain","openai-chatgpt","pinecone","llama","mistral-7b","rag","retrieval-augmented-generation","document-chat"],"created_at":"2023-06-04T02:29:14Z","pushed_at":"2024-01-13T08:32:44Z","stargazers_count":7326,"language":"Shell"},{"full_name":"promptfoo/promptfoo","description":"Test your prompts, models, RAGs. Evaluate and compare LLM outputs, catch regressions, and improve prompt quality. LLM evals for OpenAI/Azure GPT, Anthropic Claude, VertexAI Gemini, Ollama, Local & private models like Mistral/Mixtral/Llama with CI/CD","topics":["llm","prompt-engineering","prompts","llmops","prompt-testing","testing","rag","evaluation","evaluation-framework","llm-eval"],"created_at":"2023-04-28T15:48:49Z","pushed_at":"2024-01-20T00:45:30Z","stargazers_count":1748,"language":"TypeScript"},{"full_name":"infiniflow/infinity","description":"The AI-native database built for LLM applications, providing incredibly fast vector and full-text search ","topics":["ai-native","llms","nearest-neighbor-search","rag","retrieval-augmented-generation","vector-search","fused-search","information-retrival","operational-analytics","ai-native-database"],"created_at":"2022-07-18T13:52:38Z","pushed_at":"2024-01-12T00:53:08Z","stargazers_count":815,"language":"CMake"}],"frecuent_topics":{"rag":4,"llm":2,"retrieval-augmented-generation":2,"agents":1,"application":1}}