{"category_type":"topic","category_name":"transformer","repos_data":[{"full_name":"huggingface/transformers","description":"ü§ó Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.","topics":["nlp","natural-language-processing","pytorch","language-model","tensorflow","bert","language-models","pytorch-transformers","nlp-library","transformer"],"created_at":"2018-10-29T13:56:00Z","pushed_at":"2024-01-21T09:20:13Z","stargazers_count":118997,"language":"Python"},{"full_name":"labmlai/annotated_deep_learning_paper_implementations","description":"üßë‚Äçüè´ 60 Implementations/tutorials of deep learning papers with side-by-side notes üìù; including transformers (original, xl, switch, feedback, vit, ...), optimizers (adam, adabelief, sophia, ...), gans(cyclegan, stylegan2, ...), üéÆ reinforcement learning (ppo, dqn), capsnet, distillation, ... üß†","topics":["deep-learning","deep-learning-tutorial","pytorch","gan","transformers","reinforcement-learning","optimizers","neural-networks","transformer","machine-learning"],"created_at":"2020-08-25T02:29:34Z","pushed_at":"2024-01-12T07:52:00Z","stargazers_count":42454,"language":"Python"},{"full_name":"vllm-project/vllm","description":"A high-throughput and memory-efficient inference and serving engine for LLMs","topics":["gpt","llm","pytorch","llmops","mlops","model-serving","transformer","llm-serving","inference","llama"],"created_at":"2023-02-09T11:23:20Z","pushed_at":"2024-01-13T09:57:40Z","stargazers_count":13145,"language":"Python"},{"full_name":"google/trax","description":"Trax ‚Äî Deep Learning with Clear Code and Speed","topics":["jax","numpy","deep-learning","deep-reinforcement-learning","machine-learning","transformer","reinforcement-learning"],"created_at":"2019-10-05T15:09:14Z","pushed_at":"2023-12-07T17:31:04Z","stargazers_count":7857,"language":"Python"},{"full_name":"open-mmlab/mmsegmentation","description":"OpenMMLab Semantic Segmentation Toolbox and Benchmark.","topics":["semantic-segmentation","pytorch","pspnet","deeplabv3","transformer","swin-transformer","realtime-segmentation","vessel-segmentation","retinal-vessel-segmentation","image-segmentation"],"created_at":"2020-06-14T04:32:33Z","pushed_at":"2024-01-10T12:28:00Z","stargazers_count":6941,"language":"Python"},{"full_name":"huggingface/text-generation-inference","description":"Large Language Model Text Generation Inference","topics":["bloom","nlp","pytorch","inference","gpt","deep-learning","transformer","falcon","starcoder"],"created_at":"2022-10-08T10:26:28Z","pushed_at":"2024-01-11T18:52:38Z","stargazers_count":6601,"language":"Rust"},{"full_name":"codertimo/BERT-pytorch","description":"Google AI 2018 BERT pytorch implementation","topics":["bert","transformer","pytorch","nlp","language-model"],"created_at":"2018-10-15T12:58:15Z","pushed_at":"2023-09-15T12:57:08Z","stargazers_count":5831,"language":"Python"},{"full_name":"huggingface/pytorch-openai-transformer-lm","description":"üê•A PyTorch implementation of OpenAI's finetuned transformer language model with a script to import the weights pre-trained by OpenAI","topics":["neural-networks","pytorch","openai","language-model","transformer"],"created_at":"2018-06-13T14:02:41Z","pushed_at":"2021-08-09T16:17:12Z","stargazers_count":1476,"language":"Python"},{"full_name":"lemonhu/NER-BERT-pytorch","description":"PyTorch solution of named entity recognition task Using Google AI's pre-trained BERT model.","topics":["ner","named-entity-recognition","entity-extraction","chinese-ner","google-bert","transformer","msra","information-extraction","pytorch"],"created_at":"2019-01-04T08:13:41Z","pushed_at":"2023-03-30T13:57:17Z","stargazers_count":416,"language":"Python"},{"full_name":"barissayil/SentimentAnalysis","description":"Sentiment analysis neural network trained by fine-tuning BERT, ALBERT, or DistilBERT on the Stanford Sentiment Treebank.","topics":["bert","nlp","machine-learning","pytorch","pytorch-implementation","vuejs","flask","transformer","huggingface","huggingface-transformer"],"created_at":"2019-12-27T11:54:06Z","pushed_at":"2023-06-12T21:34:19Z","stargazers_count":340,"language":"Python"},{"full_name":"L0SG/relational-rnn-pytorch","description":"An implementation of DeepMind's Relational Recurrent Neural Networks (NeurIPS 2018) in PyTorch.","topics":["pytorch","language-model","word-language-model","language-modeling","deep-learning","recurrent-neural-networks","deepmind","transformer","self-attention"],"created_at":"2018-08-21T07:57:41Z","pushed_at":"2018-12-27T05:38:23Z","stargazers_count":243,"language":"Python"},{"full_name":"leviswind/pytorch-transformer","description":"pytorch implementation of Attention is all you need","topics":["pytorch","attention-is-all-you-need","translation","transformer"],"created_at":"2018-01-05T08:00:01Z","pushed_at":"2021-06-16T06:35:54Z","stargazers_count":235,"language":"Python"}],"frecuent_topics":{"transformer":12,"pytorch":11,"nlp":4,"language-model":4,"deep-learning":4}}