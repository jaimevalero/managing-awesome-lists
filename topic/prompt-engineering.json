{"category_type":"topic","category_name":"prompt-engineering","repos_data":[{"full_name":"dair-ai/Prompt-Engineering-Guide","description":"üêô Guides, papers, lecture, notebooks and resources for prompt engineering","topics":["deep-learning","prompt-engineering","openai","chatgpt","language-model"],"created_at":"2022-12-16T16:04:50Z","pushed_at":"2024-01-12T05:00:25Z","stargazers_count":39275,"language":"Jupyter Notebook"},{"full_name":"outlines-dev/outlines","description":"Guided Text Generation","topics":["generative-ai","llms","prompt-engineering","prompt-toolkit","guided-generation","symbolic-ai"],"created_at":"2023-03-17T16:01:18Z","pushed_at":"2024-01-20T10:19:30Z","stargazers_count":4173,"language":"Python"},{"full_name":"promptslab/Promptify","description":"Prompt Engineering | Prompt Versioning | Use GPT or other prompt based models to get structured output. Join our discord for Prompt-Engineering, LLMs and other latest research","topics":["chatgpt","chatgpt-api","gpt-3","gpt-3-prompts","prompt-engineering","prompt-toolkit","prompting","chatgpt-python","gpt3-library","openai"],"created_at":"2022-12-12T18:06:32Z","pushed_at":"2023-08-04T22:12:49Z","stargazers_count":2833,"language":"Python"},{"full_name":"YiVal/YiVal","description":"Your Automatic Prompt Engineering Assistant for GenAI Applications","topics":["ai","prompt","llm","ai-experiments","ai-toolkit","promptengineering","aigc","generative-ai","prompt-engineering","fine-tuning"],"created_at":"2023-07-15T02:04:35Z","pushed_at":"2024-01-12T07:02:09Z","stargazers_count":2305,"language":"Python"},{"full_name":"hegelai/prompttools","description":"Open-source tools for prompt testing and experimentation, with support for both LLMs (e.g. OpenAI, LLaMA) and vector databases (e.g. Chroma, Weaviate, LanceDB).","topics":["deep-learning","large-language-models","machine-learning","prompt-engineering","python","embeddings","llms","vector-search","developer-tools"],"created_at":"2023-06-25T19:33:00Z","pushed_at":"2024-01-03T16:45:42Z","stargazers_count":2097,"language":"Python"},{"full_name":"promptfoo/promptfoo","description":"Test your prompts, models, RAGs. Evaluate and compare LLM outputs, catch regressions, and improve prompt quality. LLM evals for OpenAI/Azure GPT, Anthropic Claude, VertexAI Gemini, Ollama, Local & private models like Mistral/Mixtral/Llama with CI/CD","topics":["llm","prompt-engineering","prompts","llmops","prompt-testing","testing","rag","evaluation","evaluation-framework","llm-eval"],"created_at":"2023-04-28T15:48:49Z","pushed_at":"2024-01-20T00:45:30Z","stargazers_count":1748,"language":"TypeScript"},{"full_name":"Agenta-AI/agenta","description":"The all-in-one LLMOps platform: prompt management, evaluation, human feedback, and deployment all in one place.","topics":["langchain","llmops","large-language-models","llm","llm-tools","llms","prompt-engineering","prompt-management","llama-index","llm-evaluation"],"created_at":"2023-04-26T09:54:28Z","pushed_at":"2024-01-19T21:03:46Z","stargazers_count":636,"language":"Dockerfile"}],"frecuent_topics":{"prompt-engineering":7,"llms":3,"llm":3,"deep-learning":2,"openai":2}}