{"category_type":"topic","category_name":"lora","repos_data":[{"full_name":"microsoft/LoRA","description":"Code for loralib, an implementation of \"LoRA: Low-Rank Adaptation of Large Language Models\"","topics":["gpt-2","adaptation","language-model","gpt-3","low-rank","pytorch","deep-learning","roberta","deberta","lora"],"created_at":"2021-06-18T02:16:35Z","pushed_at":"2024-01-09T15:03:19Z","stargazers_count":7847,"language":"Python"},{"full_name":"LianjiaTech/BELLE","description":"BELLE: Be Everyone's Large Language model Engine（开源中文对话大模型）","topics":["bloom","instruction-set","llama","open-models","gpt-q","instruct-gpt","gpt-evaluation","chinese-nlp","lora","instruct-finetune"],"created_at":"2023-03-17T09:44:11Z","pushed_at":"2023-12-29T08:39:14Z","stargazers_count":7153,"language":"Python"}],"frecuent_topics":{"lora":2,"gpt-2":1,"adaptation":1,"language-model":1,"gpt-3":1}}