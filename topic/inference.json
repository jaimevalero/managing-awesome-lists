{"category_type":"topic","category_name":"inference","repos_data":[{"full_name":"hpcaitech/ColossalAI","description":"Making large AI models cheaper, faster and more accessible","topics":["deep-learning","hpc","large-scale","data-parallelism","pipeline-parallelism","model-parallelism","ai","big-model","distributed-computing","inference"],"created_at":"2021-10-28T16:19:44Z","pushed_at":"2024-01-13T04:48:09Z","stargazers_count":36094,"language":"Python"},{"full_name":"microsoft/DeepSpeed","description":"DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective.","topics":["deep-learning","pytorch","gpu","machine-learning","billion-parameters","data-parallelism","model-parallelism","inference","pipeline-parallelism","compression"],"created_at":"2020-01-23T18:35:18Z","pushed_at":"2024-01-13T07:20:25Z","stargazers_count":30732,"language":"Python"},{"full_name":"Tencent/ncnn","description":"ncnn is a high-performance neural network inference framework optimized for the mobile platform","topics":["inference","high-preformance","simd","arm-neon","deep-learning","artificial-intelligence","android","ios","ncnn","vulkan"],"created_at":"2017-06-30T10:55:37Z","pushed_at":"2024-01-12T07:49:57Z","stargazers_count":18603,"language":"CMake"},{"full_name":"vllm-project/vllm","description":"A high-throughput and memory-efficient inference and serving engine for LLMs","topics":["gpt","llm","pytorch","llmops","mlops","model-serving","transformer","llm-serving","inference","llama"],"created_at":"2023-02-09T11:23:20Z","pushed_at":"2024-01-13T09:57:40Z","stargazers_count":13145,"language":"Python"},{"full_name":"huggingface/text-generation-inference","description":"Large Language Model Text Generation Inference","topics":["bloom","nlp","pytorch","inference","gpt","deep-learning","transformer","falcon","starcoder"],"created_at":"2022-10-08T10:26:28Z","pushed_at":"2024-01-11T18:52:38Z","stargazers_count":6601,"language":"Rust"},{"full_name":"microsoft/DeepSpeed-MII","description":"MII makes low-latency and high-throughput inference possible, powered by DeepSpeed.","topics":["deep-learning","inference","pytorch"],"created_at":"2022-03-23T22:30:45Z","pushed_at":"2024-01-13T02:26:38Z","stargazers_count":1374,"language":"Python"},{"full_name":"kamalkraj/BERT-NER","description":"Pytorch-Named-Entity-Recognition-with-BERT","topics":["bert","named-entity-recognition","pytorch","conll-2003","cpp11","bert-ner","inference","curl","postman","pretrained-models"],"created_at":"2019-02-24T10:40:46Z","pushed_at":"2021-05-06T19:38:36Z","stargazers_count":1164,"language":"Python"},{"full_name":"xboot/libonnx","description":"A lightweight, portable pure C99 onnx inference engine for embedded devices with hardware acceleration support.","topics":["onnx","inference","c","embedded","baremetal","library","deep-learning","embedded-systems","portable","lightweight"],"created_at":"2020-10-14T01:20:39Z","pushed_at":"2023-02-13T07:18:28Z","stargazers_count":534,"language":"Makefile"},{"full_name":"dmmiller612/sparktorch","description":"Train and run Pytorch models on Apache Spark.","topics":["pytorch","sparktorch","deep-learning","apache-spark","pipelines","inference","distributed-computing"],"created_at":"2019-11-29T18:38:53Z","pushed_at":"2023-05-11T15:31:19Z","stargazers_count":329,"language":"Dockerfile"},{"full_name":"Media-Smart/volksdep","description":"volksdep is an open-source toolbox for deploying and accelerating PyTorch, ONNX and TensorFlow models with TensorRT.","topics":["pytorch","onnx","tensorrt","deploy","tensorflow","jetson-nano","jetson-tx2","jetson-xavier","inference","python"],"created_at":"2020-05-21T08:43:10Z","pushed_at":"2021-02-05T02:47:21Z","stargazers_count":284,"language":"Python"},{"full_name":"Wizaron/pytorch-cpp-inference","description":"Serving PyTorch 1.0 Models as a Web Server in C++","topics":["pytorch","inference","cpp"],"created_at":"2018-10-23T19:32:53Z","pushed_at":"2020-01-15T13:39:21Z","stargazers_count":224,"language":"Dockerfile"},{"full_name":"erwanlemerrer/awesome-audit-algorithms","description":"A curated list of algorithms and papers for auditing black-box algorithms.","topics":["audit","blackbox","algorithms","reverse-engineering","inference","awesome","awesome-list"],"created_at":"2017-09-28T14:48:33Z","pushed_at":"2024-01-09T15:06:28Z","stargazers_count":77,"language":"unknown"},{"full_name":"CogComp/saul","description":"Saul : Declarative Learning-Based Programming","topics":["machine-learning-algorithms","feature-extraction","machine-learning-library","inference"],"created_at":"2015-09-30T22:21:38Z","pushed_at":"2020-01-16T15:33:51Z","stargazers_count":63,"language":"Scala"},{"full_name":"songtianyi/go-mxnet-predictor","description":" go binding for mxnet c_predict_api to do inference with pre-trained model","topics":["machine-learning","mxnet","golang","cgo","inference","deep-learning"],"created_at":"2016-12-12T10:28:04Z","pushed_at":"2018-06-06T11:41:16Z","stargazers_count":55,"language":"Go"},{"full_name":"nikolaydubina/go-ml-benchmarks","description":"‚è± Benchmarks of machine learning inference for Go","topics":["machine-learning","benchmarks","xgboost","scikit-learn","inference","grpc","go","python","cpp"],"created_at":"2021-02-09T10:20:46Z","pushed_at":"2023-07-05T21:04:03Z","stargazers_count":29,"language":"Makefile"}],"frecuent_topics":{"inference":15,"deep-learning":8,"pytorch":8,"machine-learning":3,"data-parallelism":2}}