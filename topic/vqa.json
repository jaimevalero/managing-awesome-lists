{"category_type":"topic","category_name":"vqa","repos_data":[{"full_name":"facebookresearch/mmf","description":"A modular framework for vision & language multimodal research from Facebook AI Research (FAIR)","topics":["pytorch","vqa","pretrained-models","multimodal","deep-learning","captioning","dialog","textvqa","hateful-memes","multi-tasking"],"created_at":"2018-06-27T04:52:40Z","pushed_at":"2024-01-18T21:14:52Z","stargazers_count":5357,"language":"Python"},{"full_name":"hengyuan-hu/bottom-up-attention-vqa","description":"An efficient PyTorch implementation of the winning entry of the 2017 VQA Challenge.","topics":["vqa","pytorch","bottom-up-attention"],"created_at":"2017-12-16T05:00:41Z","pushed_at":"2019-09-04T22:22:55Z","stargazers_count":742,"language":"Python"},{"full_name":"Cadene/vqa.pytorch","description":"Visual Question Answering in Pytorch","topics":["vqa","deep-learning","resnet","skipthoughts","pytorch","clevr","coco","torch","vgenome"],"created_at":"2017-05-17T19:41:04Z","pushed_at":"2019-12-11T23:54:10Z","stargazers_count":698,"language":"Python"},{"full_name":"davidmascharka/tbd-nets","description":"PyTorch implementation of \"Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning\"","topics":["machine-learning","pytorch","visualization","deep-learning","visual-question-answering","vqa","neural-networks"],"created_at":"2018-03-13T18:54:02Z","pushed_at":"2021-12-07T20:02:33Z","stargazers_count":352,"language":"Jupyter Notebook"}],"frecuent_topics":{"pytorch":4,"vqa":4,"deep-learning":3,"pretrained-models":1,"multimodal":1}}